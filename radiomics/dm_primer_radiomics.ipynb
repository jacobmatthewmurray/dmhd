{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.digitale-medizin.net/img/Main_Day1_Healthcare_MOV8_Patient_v06.gif\" alt=\"header_image\"\n",
    "\ttitle=\"dmhd\" width=100% height=\"200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:45px\">Digitale Medizin: Primer on Radiomics</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will focus on three things:\n",
    "- Analyzing 2D image data\n",
    "- Segmenting liver lesions\n",
    "- Conducting a simple feature calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks allow for a rich, interactive programming experience with different programming languages (e.g., Python, R, SAS). In this tutorial we will use Python, a common, versatile scripting language that is - perhaps- the current international standard in scientific computing, including machine learning and health data analysis applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To execute the code in a cell hit the 'Run' button above or `Ctrl + K`.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most scripts start with imports of libraries, that provide additional functionality, needed to run the code. \n",
    "\n",
    "_Go ahead, select the next cell and run it to import the libraries we will need for this tutorial._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nrrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import describe\n",
    "from simple_segmenter import make_simple_segmenter\n",
    "from base64 import b64decode\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from skimage.measure import perimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analyzing 2D Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image we are working with is from a public dataset of livers with lesions (LiTS). To start, let's make a variable specifying where the image is located. Then we will load the image and convert it to a matrix (array) of numbers, before analyzing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './data/lits_liver.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)\n",
    "image_array = np.array(image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the image is:  (512, 512)\n",
      "The size of the array is:  (512, 512, 4)\n"
     ]
    }
   ],
   "source": [
    "# the size of the image and the shape of the corresponding array\n",
    "print('The size of the image is: ', image.size)\n",
    "print('The size of the array is: ', image_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A center point in the 4D gray-scale array: [211 211 211 255]\n"
     ]
    }
   ],
   "source": [
    "# let us look at poin in the gray-scale array to get sense of what it means\n",
    "print('A center point in the 4D gray-scale array:', image_array[256, 256, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see four channels in the image: RGB (red, green, blue) + A (alpha)\n",
    "\n",
    "The A channel regulates the transparency of the image. When working with segmentation masks, that we want to display above original images, this is an important piece of information to bear in mind.\n",
    "\n",
    "Original DICOM image data (or data stored in NiFTY or NRRD files) is not mapped onto the 8 bit interval (0-255). Instead, it is often recorded in 12 bit (0-4095) and linearly transformed according to $f(x) = x - 1024$. Thus, the Hounsfield Unit of -1024 for air can be represented. \n",
    "\n",
    "In preparing this tutorial, the original DICOM image was converted and mapped to (0-255). Additionally, since we are working with gray-scale images, the first three channels are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Questions:_\n",
    "- What information do we not have in a simple array of pixel values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Let us calculate some descriptive statistics for our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array[..., 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=262144, minmax=(0, 255), mean=50.19119644165039, variance=5108.56604999236, skewness=1.1534018163260666, kurtosis=-0.06894553552158467)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to describe our array we can use the scipy describe package, which we have imported\n",
    "describe(image_array[..., 0].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A very common way to analyze image information is to look at the histogram of pixel values.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/home/jacob/.pyenv/versions/3.7.4/envs/dmhd/lib/python3.7/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(image_array[..., 0].flatten())\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Questions:_\n",
    "- In which scenarios do want to use histogram information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Segmenting a 2D Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built a very simple segmentation tool for you. To make segmentations, run the next cell. In the image click the left mouse button and keep it pressed to circle an area to be segmented. Once you are finished, click the 'Get Segmentation Mask' button and you will have the segmentation information stored in the variable `dataURL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h1>Simple Segmenter</h1>\n",
       "    <p>\n",
       "    <div id=\"container\">\n",
       "    <canvas id=\"imageView\" width=512 height=512 style = \"cursor:crosshair\"></canvas>\n",
       "    </div>\n",
       "    <button onclick=\"get_mask()\">Get Segmentation Mask</button>\n",
       "    <button onclick=\"clear_canvas()\">Clear Segmentation</button>\n",
       "    <script>\n",
       "    var canvas, context;\n",
       "\n",
       "      function init () {\n",
       "\n",
       "        // Find the canvas element.\n",
       "        canvas = document.getElementById('imageView');\n",
       "        if (!canvas) {\n",
       "          alert('Error: I cannot find the canvas element!');\n",
       "          return;\n",
       "        }\n",
       "\n",
       "        if (!canvas.getContext) {\n",
       "          alert('Error: no canvas.getContext!');\n",
       "          return;\n",
       "        }\n",
       "\n",
       "        // Get the 2D canvas context.\n",
       "        context = canvas.getContext('2d');\n",
       "        if (!context) {\n",
       "          alert('Error: failed to getContext!');\n",
       "          return;\n",
       "        }\n",
       "\n",
       "        context.strokeStyle = 'red';\n",
       "        context.lineWidth = 2;\n",
       "        context.fillStyle = 'rgba(255,0,0,0.2)'\n",
       "\n",
       "\n",
       "    \ttool = new tool_pencil();\n",
       "\n",
       "    \t// Attach the mousedown, mousemove and mouseup event listeners\n",
       "    \tcanvas.addEventListener('mousedown', ev_canvas, false);\n",
       "    \tcanvas.addEventListener('mousemove', ev_canvas, false);\n",
       "    \tcanvas.addEventListener('mouseup',\t ev_canvas, false);\n",
       "\n",
       "        canvas.style.background = \"url(./lits_liver.png)\";\n",
       "    }\n",
       "\n",
       "    // This painting tool works like a drawing\n",
       "    // pencil which tracks the mouse movements\n",
       "    function tool_pencil () {\n",
       "    \tvar tool = this;\n",
       "    \tthis.started = false;\n",
       "\n",
       "    \t// This is called when you start holding down the mouse button\n",
       "    \t// This starts the pencil drawing\n",
       "    \tthis.mousedown = function (ev) {\n",
       "    \t\t\tcontext.beginPath();\n",
       "    \t\t\tcontext.moveTo(ev._x, ev._y);\n",
       "    \t\t\ttool.started = true;\n",
       "    \t};\n",
       "\n",
       "    \t// This function is called every time you move the mouse. Obviously, it only\n",
       "    \t// draws if the tool.started state is set to true (when you are holding down\n",
       "    \t// the mouse button)\n",
       "    \tthis.mousemove = function (ev) {\n",
       "    \t\tif (tool.started) {\n",
       "    \t\t\tcontext.lineTo(ev._x, ev._y);\n",
       "    \t\t\tcontext.stroke();\n",
       "    \t\t}\n",
       "    \t};\n",
       "\n",
       "    \t// This is called when you release the mouse button\n",
       "    \tthis.mouseup = function (ev) {\n",
       "    \t\tif (tool.started) {\n",
       "    \t\t\ttool.mousemove(ev);\n",
       "    \t\t\ttool.started = false;\n",
       "                context.closePath();\n",
       "                context.stroke();\n",
       "                context.fill();\n",
       "    \t\t}\n",
       "    \t};\n",
       "    }\n",
       "\n",
       "    // The general-purpose event handler. This function just determines\n",
       "    // the mouse position relative to the <canvas> element\n",
       "    function ev_canvas (ev) {\n",
       "\n",
       "\n",
       "        var rect = canvas.getBoundingClientRect();\n",
       "\n",
       "        ev._x = ev.clientX - rect.left;\n",
       "        ev._y = ev.clientY - rect.top;\n",
       "\n",
       "    \t// Call the event handler of the tool\n",
       "    \tvar func = tool[ev.type];\n",
       "    \tif (func) {\n",
       "    \t\tfunc(ev);\n",
       "    \t}\n",
       "    }\n",
       "\n",
       "    function clear_canvas() {\n",
       "        context.clearRect(0, 0, canvas.width, canvas.height);\n",
       "    }\n",
       "\n",
       "    function get_mask () {\n",
       "        var command = \"dataURL = '\" + canvas.toDataURL() + \"'\";\n",
       "        console.log(\"Executing Command: \" + command);\n",
       "\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute(command);\n",
       "    }\n",
       "\n",
       "      init();\n",
       "            </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_simple_segmenter(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAYAAAD0eNT6AAAFPElEQVR4nO3dy2rjMBgG0M+lt0XbpxmGmV3frI/XRfs0ZTalgzWLupCE3EiakRWdA4ZgZPMvZOtThFECAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA0JqSjBuOp9q1AdQw1C4ATqkkH0kut7UZPAdAh7a+GKFlJSm1awCYKwGAs1CSceXU6qz+x5rLXk9UDsDsCQA0aZrdf83wt/2F/zfJr9NXBNAWAYCW7Vq7N/gDbCAAcC4OHuxL8jYkD99cD8CsCQC0bt3a/r7+JLlLcl+S9yG5+aaaAGbvonYBUNFjPj8TTJLrinUA/HcCAL37XbsAgBoEAADokAAAAB0SAACgQwIAAHRIAACADgkAtO7lyOvtBwB0SQCgVYv7ADwfeI/F8PB+XDkAbREAaNKw3HevDrjFaxb2EhiS26OLAmjIrs1UYLbK56z9evnUpqb5Of3+mvUv9f3BswB0xkuPppVkzH79uKxrZ+AHemUJgKZNSwHjfk0BgG6UZCxJmY6P3VcAAGdhCgEGfwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAzso/ymU83At4Gj8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=512x512 at 0x7FD2522154D0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation_mask = Image.open(BytesIO(b64decode(dataURL.split(',')[1])))\n",
    "segmentation_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important:__ So what is a segmentation mask? What we see above and what is stored in the variable `segmentation_mask` is again an RGBA image. However, ultimately we want a matrix of 1s and 0s of the same size as the image. This will allow us to piece-wise multiply the two matrices and to isolate only those pixels that have a corresponding mask value of 1.\n",
    "\n",
    "For example:\n",
    "\n",
    "$ \\begin{bmatrix}2 & 3 & 7 \\\\ 4 & 8 & 8\\\\ 2 & 5 & 1 \\end{bmatrix} \\odot \\begin{bmatrix}0 & 0 & 1 \\\\ 0 & 1 & 1\\\\ 0 & 0 & 1 \\end{bmatrix} = \\begin{bmatrix}0 & 0 & 7 \\\\ 0 & 8 & 8\\\\ 0 & 0 & 1 \\end{bmatrix} $\n",
    "\n",
    "Therefore, we convert the RGBA mask to a binary array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert segmentation to binary mask\n",
    "segmentation_mask_array = np.array(segmentation_mask)\n",
    "binary_segmentation_mask = np.sum(segmentation_mask_array[..., :3], axis=-1) != 0\n",
    "binary_segmentation_mask = binary_segmentation_mask.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original image for header and save segmentation\n",
    "img_data, img_head = nrrd.read('./data/lits_liver.nrrd')\n",
    "nrrd.write('./data/lits_liver_segmentation.nrrd', binary_segmentation_mask, header=img_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running a Simple Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Simple Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple features of the lesion can be calculated solely based on the segmentation mask. Two such features, that we want to calculate here are _PixelsInLesion_ and _LesionPerimeter_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixels_in_lesion(binary_segmentation_mask):\n",
    "    return np.sum(binary_segmentation_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels_in_lesion(binary_segmentation_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesion_perimeter(binary_segmentation_mask):\n",
    "    return perimeter(binary_segmentation_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.21320343559643"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesion_perimeter(binary_segmentation_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Complex Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex features can be caluculated with a variety of tools, i.e., 3D Slicer, MITK, MintMedical. A commonly used libarary for Python is pyradiomics, which is what we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import six\n",
    "\n",
    "from radiomics import featureextractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrrd_image_path = './data/lits_liver.nrrd'\n",
    "nrrd_segmentation_path = './data/lits_liver_segmentation.nrrd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shape features are only available 3D input (for 2D input, use shape2D). Found 2D input\n",
      "GLCM is symmetrical, therefore Sum Average = 2 * Joint Average, only 1 needs to be calculated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tdiagnostics_Versions_PyRadiomics: 2.2.0\n",
      "\tdiagnostics_Versions_Numpy: 1.17.4\n",
      "\tdiagnostics_Versions_SimpleITK: 1.2.4\n",
      "\tdiagnostics_Versions_PyWavelet: 1.0.0\n",
      "\tdiagnostics_Versions_Python: 3.7.4\n",
      "\tdiagnostics_Configuration_Settings: {'minimumROIDimensions': 2, 'minimumROISize': None, 'normalize': False, 'normalizeScale': 1, 'removeOutliers': None, 'resampledPixelSpacing': None, 'interpolator': 'sitkBSpline', 'preCrop': False, 'padDistance': 5, 'distances': [1], 'force2D': False, 'force2Ddimension': 0, 'resegmentRange': None, 'label': 1, 'additionalInfo': True}\n",
      "\tdiagnostics_Configuration_EnabledImageTypes: {'Original': {}}\n",
      "\tdiagnostics_Image-original_Hash: b51487610a3459f9785662535f72609587c54436\n",
      "\tdiagnostics_Image-original_Dimensionality: 2D\n",
      "\tdiagnostics_Image-original_Spacing: (1.0, 1.0)\n",
      "\tdiagnostics_Image-original_Size: (512, 512)\n",
      "\tdiagnostics_Image-original_Mean: 50.24042892456055\n",
      "\tdiagnostics_Image-original_Minimum: 0.0\n",
      "\tdiagnostics_Image-original_Maximum: 255.0\n",
      "\tdiagnostics_Mask-original_Hash: 5e7f5e6c79e31a3d4ba1e52e1d906062fb8d91a8\n",
      "\tdiagnostics_Mask-original_Spacing: (1.0, 1.0)\n",
      "\tdiagnostics_Mask-original_Size: (512, 512)\n",
      "\tdiagnostics_Mask-original_BoundingBox: (313, 174, 23, 21)\n",
      "\tdiagnostics_Mask-original_VoxelNum: 384\n",
      "\tdiagnostics_Mask-original_VolumeNum: 1\n",
      "\tdiagnostics_Mask-original_CenterOfMassIndex: (323.8776041666667, 184.20833333333334)\n",
      "\tdiagnostics_Mask-original_CenterOfMass: (323.8776041666667, 184.20833333333334)\n",
      "\toriginal_firstorder_10Percentile: 121.0\n",
      "\toriginal_firstorder_90Percentile: 165.7\n",
      "\toriginal_firstorder_Energy: 7895653.0\n",
      "\toriginal_firstorder_Entropy: 1.5604404686424718\n",
      "\toriginal_firstorder_InterquartileRange: 21.25\n",
      "\toriginal_firstorder_Kurtosis: 2.5984754442948383\n",
      "\toriginal_firstorder_Maximum: 187.0\n",
      "\toriginal_firstorder_MeanAbsoluteDeviation: 13.42529296875\n",
      "\toriginal_firstorder_Mean: 142.4296875\n",
      "\toriginal_firstorder_Median: 141.0\n",
      "\toriginal_firstorder_Minimum: 103.0\n",
      "\toriginal_firstorder_Range: 84.0\n",
      "\toriginal_firstorder_RobustMeanAbsoluteDeviation: 9.5648767817681\n",
      "\toriginal_firstorder_RootMeanSquared: 143.39315309374666\n",
      "\toriginal_firstorder_Skewness: 0.26953134054607764\n",
      "\toriginal_firstorder_TotalEnergy: 7895653.0\n",
      "\toriginal_firstorder_Uniformity: 0.3973388671875\n",
      "\toriginal_firstorder_Variance: 275.38047281901044\n",
      "\toriginal_glcm_Autocorrelation: 5.124650762643498\n",
      "\toriginal_glcm_ClusterProminence: 7.908167989578797\n",
      "\toriginal_glcm_ClusterShade: 0.6732612542282874\n",
      "\toriginal_glcm_ClusterTendency: 1.6543293199365217\n",
      "\toriginal_glcm_Contrast: 0.34983649985424753\n",
      "\toriginal_glcm_Correlation: 0.6507634594954683\n",
      "\toriginal_glcm_DifferenceAverage: 0.3469629366358567\n",
      "\toriginal_glcm_DifferenceEntropy: 0.9324801925638332\n",
      "\toriginal_glcm_DifferenceVariance: 0.2265626075674919\n",
      "\toriginal_glcm_Id: 0.8269974588851368\n",
      "\toriginal_glcm_Idm: 0.8268058880039106\n",
      "\toriginal_glcm_Idmn: 0.9794720923006629\n",
      "\toriginal_glcm_Idn: 0.9307031981134416\n",
      "\toriginal_glcm_Imc1: -0.27000202708578813\n",
      "\toriginal_glcm_Imc2: 0.7449595030554426\n",
      "\toriginal_glcm_InverseVariance: 0.34444856881976477\n",
      "\toriginal_glcm_JointAverage: 2.1905317501585664\n",
      "\toriginal_glcm_JointEnergy: 0.22107459551873135\n",
      "\toriginal_glcm_JointEntropy: 2.6591040371044232\n",
      "\toriginal_glcm_MCC: 0.6741965469018482\n",
      "\toriginal_glcm_MaximumProbability: 0.4008306350921905\n",
      "\toriginal_glcm_SumAverage: 4.381063500317134\n",
      "\toriginal_glcm_SumEntropy: 2.3028522375003164\n",
      "\toriginal_glcm_SumSquares: 0.5010414549476923\n",
      "\toriginal_gldm_DependenceEntropy: 4.34388523371077\n",
      "\toriginal_gldm_DependenceNonUniformity: 53.364583333333336\n",
      "\toriginal_gldm_DependenceNonUniformityNormalized: 0.1389702690972222\n",
      "\toriginal_gldm_DependenceVariance: 3.8417697482638893\n",
      "\toriginal_gldm_GrayLevelNonUniformity: 152.578125\n",
      "\toriginal_gldm_GrayLevelVariance: 0.51898193359375\n",
      "\toriginal_gldm_HighGrayLevelEmphasis: 5.4765625\n",
      "\toriginal_gldm_LargeDependenceEmphasis: 38.052083333333336\n",
      "\toriginal_gldm_LargeDependenceHighGrayLevelEmphasis: 195.0078125\n",
      "\toriginal_gldm_LargeDependenceLowGrayLevelEmphasis: 10.826587818287038\n",
      "\toriginal_gldm_LowGrayLevelEmphasis: 0.30322265625\n",
      "\toriginal_gldm_SmallDependenceEmphasis: 0.05214292111520533\n",
      "\toriginal_gldm_SmallDependenceHighGrayLevelEmphasis: 0.3037321914925306\n",
      "\toriginal_gldm_SmallDependenceLowGrayLevelEmphasis: 0.01849684496944783\n",
      "\toriginal_glrlm_GrayLevelNonUniformity: 50.38332003220217\n",
      "\toriginal_glrlm_GrayLevelNonUniformityNormalized: 0.33351382253786066\n",
      "\toriginal_glrlm_GrayLevelVariance: 0.6750768876490949\n",
      "\toriginal_glrlm_HighGrayLevelRunEmphasis: 5.892624298846769\n",
      "\toriginal_glrlm_LongRunEmphasis: 10.9528345561417\n",
      "\toriginal_glrlm_LongRunHighGrayLevelEmphasis: 55.477318611086034\n",
      "\toriginal_glrlm_LongRunLowGrayLevelEmphasis: 3.133930750771923\n",
      "\toriginal_glrlm_LowGrayLevelRunEmphasis: 0.3204871223802394\n",
      "\toriginal_glrlm_RunEntropy: 3.98809522657399\n",
      "\toriginal_glrlm_RunLengthNonUniformity: 38.93376506028413\n",
      "\toriginal_glrlm_RunLengthNonUniformityNormalized: 0.2517703215714401\n",
      "\toriginal_glrlm_RunPercentage: 0.3938802083333333\n",
      "\toriginal_glrlm_RunVariance: 4.103230898791148\n",
      "\toriginal_glrlm_ShortRunEmphasis: 0.4872584619090619\n",
      "\toriginal_glrlm_ShortRunHighGrayLevelEmphasis: 3.024566536109176\n",
      "\toriginal_glrlm_ShortRunLowGrayLevelEmphasis: 0.16534775964728526\n",
      "\toriginal_glszm_GrayLevelNonUniformity: 3.1666666666666665\n",
      "\toriginal_glszm_GrayLevelNonUniformityNormalized: 0.2638888888888889\n",
      "\toriginal_glszm_GrayLevelVariance: 1.4097222222222223\n",
      "\toriginal_glszm_HighGrayLevelZoneEmphasis: 7.25\n",
      "\toriginal_glszm_LargeAreaEmphasis: 4392.833333333333\n",
      "\toriginal_glszm_LargeAreaHighGrayLevelEmphasis: 20178.583333333332\n",
      "\toriginal_glszm_LargeAreaLowGrayLevelEmphasis: 1127.046875\n",
      "\toriginal_glszm_LowGrayLevelZoneEmphasis: 0.41840277777777773\n",
      "\toriginal_glszm_SizeZoneNonUniformity: 1.8333333333333333\n",
      "\toriginal_glszm_SizeZoneNonUniformityNormalized: 0.1527777777777778\n",
      "\toriginal_glszm_SmallAreaEmphasis: 0.21316948909414665\n",
      "\toriginal_glszm_SmallAreaHighGrayLevelEmphasis: 0.7468416377480073\n",
      "\toriginal_glszm_SmallAreaLowGrayLevelEmphasis: 0.12927688137628315\n",
      "\toriginal_glszm_ZoneEntropy: 3.4182958340544856\n",
      "\toriginal_glszm_ZonePercentage: 0.03125\n",
      "\toriginal_glszm_ZoneVariance: 3368.833333333333\n",
      "\toriginal_ngtdm_Busyness: 5.736309523809524\n",
      "\toriginal_ngtdm_Coarseness: 0.024413564696059976\n",
      "\toriginal_ngtdm_Complexity: 1.81777510304381\n",
      "\toriginal_ngtdm_Contrast: 0.027130063753279435\n",
      "\toriginal_ngtdm_Strength: 0.12246471355711064\n"
     ]
    }
   ],
   "source": [
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "result = extractor.execute(nrrd_image_path, nrrd_segmentation_path)\n",
    "for key, val in six.iteritems(result):\n",
    "  print(\"\\t%s: %s\" %(key, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps would be use the features extracted above for many different liver lesions in order to build a model that accurately classifies lesions with characteristics of interest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
